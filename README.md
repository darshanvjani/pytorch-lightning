![pytorch_lightning](https://github.com/darshanvjani/pytorch-lightning/blob/main/Images/pytorch_ligh_img.png?raw=true)


PyTorch Lightning is a lightweight PyTorch wrapper that decouples the science code from the engineering code. It's designed to simplify the process of writing distributed deep learning code. With PyTorch Lightning, researchers and developers can maintain the flexibility and control that PyTorch offers, while also streamlining the training process, improving reproducibility, and ensuring production-readiness.

## Why is PyTorch Lightning Useful?

- **Simplicity**: Decouples the science code from the engineering code, reducing boilerplate.
- **Scalability**: Easily run models on multiple GPUs, TPUs, or in a distributed setting.
- **Reproducibility**: Ensures consistent results across runs.
- **Tool Integration**: Works seamlessly with popular logging and visualization tools.
- **Production-Ready**: Facilitates smooth transition from research to deployment.

## Repository Structure

![Repository Structure Diagram](https://showme.redstarplugin.com/d/uTBv3J5D)

[You can view this diagram in a new tab.](https://showme.redstarplugin.com/d/uTBv3J5D)


## Contents

- **[Lightning Trainer](./3.%20Lightning%20Trainer/)**: Dive deep into the core of the PyTorch Lightning framework, understanding the intricacies of the training loop and resource management.
- **[metrics](./4.%20metrics/)**: Metrics are pivotal in evaluating the performance of deep learning models. Explore the various metrics utilized within the PyTorch Lightning ecosystem.
- **[data module](./5.%20data%20module/)**: Data handling is streamlined in PyTorch Lightning. Discover how data modules manage preprocessing, augmentation, and loading.
- **[code restructuring](./6.%20code%20restructuring/)**: Learn about best practices for organizing your PyTorch Lightning code, ensuring clarity and scalability.
- **[callbacks](./7.%20callbacks/)**: Delve into the world of callbacks in PyTorch Lightning, which offer flexibility during training, model saving, and more.
- **[Logging Tensorboard](./8.%20Logging%20Tensorboard/)**: Understand the integration of PyTorch Lightning with Tensorboard, offering insights into training metrics and visualizations.
- **[Profiler](./9.%20Profiler/)**: Performance optimization is key. Explore the built-in profiler to identify bottlenecks and enhance your training routines.

## Contribution

Your insights and contributions are invaluable. Whether you're improving documentation, introducing new features, or reporting bugs, I appreciate your efforts. Feel free to raise issues or submit pull requests.
